{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognizing Top Organizations and Locations with SpaCy and NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author - Lasya Nayani Bhatta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\manoj\\appdata\\roaming\\python\\python310\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read news data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample contains 10,012 news articles\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>language</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://kokomoperspective.com/obituaries/jon-w-horton/article_b6ba8e1e-cb9c-11eb-9868-fb11b88b9778.html</td>\n",
       "      <td>2021-06-13</td>\n",
       "      <td>en</td>\n",
       "      <td>Jon W. Horton | Obituaries | kokomoperspective.com</td>\n",
       "      <td>Jon W. Horton | Obituaries | kokomoperspective.comYou have permission to edit this article. EditCloseSign Up                        Log In                    Dashboard  LogoutMy Account Dashboard Profile Saved items LogoutCOVID-19Click here for the latest local news on COVID-19HomeAbout UsContact UsNewsLocalOpinionPoliticsNationalStateAgricultureLifestylesEngagements/Anniversaries/WeddingsAutosEntertainmentHealthHomesOutdoorsSportsNFLNCAAVitalsObituariesAutomotivee-EditionCouponsGalleries74°...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://auto.economictimes.indiatimes.com/news/auto-components/birla-precision-to-ramp-up-capacity-to-tap-emerging-opportunities-in-india/81254902</td>\n",
       "      <td>2021-02-28</td>\n",
       "      <td>en</td>\n",
       "      <td>Birla Precision to ramp up capacity to tap emerging opportunities in India, Auto News, ET Auto</td>\n",
       "      <td>Birla Precision to ramp up capacity to tap emerging opportunities in India, Auto News, ET Auto     We have updated our terms and conditions and privacy policy Click \"Continue\" to accept and continue with ET AutoAccept the updated privacy &amp; cookie policyDear user, ET Auto privacy and cookie policy has been updated to align with the new data regulations in European Union. Please review and accept these changes below to continue using the website.You can see our privacy policy &amp; our cookie ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                  url  \\\n",
       "0                                              http://kokomoperspective.com/obituaries/jon-w-horton/article_b6ba8e1e-cb9c-11eb-9868-fb11b88b9778.html   \n",
       "1  https://auto.economictimes.indiatimes.com/news/auto-components/birla-precision-to-ramp-up-capacity-to-tap-emerging-opportunities-in-india/81254902   \n",
       "\n",
       "        date language  \\\n",
       "0 2021-06-13       en   \n",
       "1 2021-02-28       en   \n",
       "\n",
       "                                                                                                 title  \\\n",
       "0                                                   Jon W. Horton | Obituaries | kokomoperspective.com   \n",
       "1       Birla Precision to ramp up capacity to tap emerging opportunities in India, Auto News, ET Auto   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  text  \n",
       "0  Jon W. Horton | Obituaries | kokomoperspective.comYou have permission to edit this article. EditCloseSign Up                        Log In                    Dashboard  LogoutMy Account Dashboard Profile Saved items LogoutCOVID-19Click here for the latest local news on COVID-19HomeAbout UsContact UsNewsLocalOpinionPoliticsNationalStateAgricultureLifestylesEngagements/Anniversaries/WeddingsAutosEntertainmentHealthHomesOutdoorsSportsNFLNCAAVitalsObituariesAutomotivee-EditionCouponsGalleries74°...  \n",
       "1      Birla Precision to ramp up capacity to tap emerging opportunities in India, Auto News, ET Auto     We have updated our terms and conditions and privacy policy Click \"Continue\" to accept and continue with ET AutoAccept the updated privacy & cookie policyDear user, ET Auto privacy and cookie policy has been updated to align with the new data regulations in European Union. Please review and accept these changes below to continue using the website.You can see our privacy policy & our cookie ...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_path = 'https://storage.googleapis.com/msca-bdp-data-open/news/nlp_a_5_news.json'\n",
    "news_df = pd.read_json(news_path, orient='records', lines=True)\n",
    "\n",
    "print(f'Sample contains {news_df.shape[0]:,.0f} news articles')\n",
    "news_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning News Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) Cleaning Title**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mentions exist in titles: True\n",
      "Hashtags exist in titles: True\n",
      "Numbers exist in titles: True\n",
      "Links exist in titles: False\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "# Check if mentions exist\n",
    "mentions_exist_title = any('@' in title for title in news_df['title'])\n",
    "\n",
    "# Check if hashtags exist\n",
    "hashtags_exist_title = any('#' in title for title in news_df['title'])\n",
    "\n",
    "# Check if numbers exist\n",
    "numbers_exist_title = any(re.search(r'\\d', title) for title in news_df['title'])\n",
    "\n",
    "# Check if links exist\n",
    "links_exist_title = any(re.search(r'https?://\\S+', title) for title in news_df['title'])\n",
    "\n",
    "print(\"Mentions exist in titles:\", mentions_exist_title)\n",
    "print(\"Hashtags exist in titles:\", hashtags_exist_title)\n",
    "print(\"Numbers exist in titles:\", numbers_exist_title)\n",
    "print(\"Links exist in titles:\", links_exist_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cleanTitle(title):\n",
    "    # Remove mentions if they exist\n",
    "    title = re.sub('@[A-Za-z0-9_]+', '', title)\n",
    "    \n",
    "    # Remove hashtags if they exist\n",
    "    title = re.sub('#', '', title)\n",
    "    \n",
    "    # Remove hyperlinks if they exist\n",
    "    title = re.sub(r'https?://\\S+', '', title)\n",
    "    \n",
    "    # Remove pipe characters if they exist\n",
    "    title = title.replace('|', '')\n",
    "    \n",
    "    # Remove any remaining non-alphanumeric characters and extra whitespaces\n",
    "    title = re.sub(r'[^a-zA-Z0-9\\s]', '', title)\n",
    "    title = re.sub(r'\\s+', ' ', title).strip()\n",
    "    \n",
    "    return title.strip()\n",
    "\n",
    "# Apply the updated cleaning function to the 'title' column in news_df\n",
    "news_df['cleanedTitle'] = news_df['title'].apply(cleanTitle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mentions exist: True\n",
      "Hashtags exist: True\n",
      "Numbers exist: True\n",
      "Links exist: True\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "# Check if mentions exist\n",
    "mentions_exist = any('@' in text for text in news_df['text'])\n",
    "\n",
    "# Check if hashtags exist\n",
    "hashtags_exist = any('#' in text for text in news_df['text'])\n",
    "\n",
    "# Check if numbers exist\n",
    "numbers_exist = any(re.search(r'\\d', text) for text in news_df['text'])\n",
    "\n",
    "# Check if links exist\n",
    "links_exist = any(re.search(r'https?://\\S+', text) for text in news_df['text'])\n",
    "\n",
    "print(\"Mentions exist:\", mentions_exist)\n",
    "print(\"Hashtags exist:\", hashtags_exist)\n",
    "print(\"Numbers exist:\", numbers_exist)\n",
    "print(\"Links exist:\", links_exist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cleanNews(text):\n",
    "    # Remove mentions (@username)\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+', '', text)\n",
    "    \n",
    "    # Remove hashtags (#)\n",
    "    text = re.sub(r'#', '', text)\n",
    "    \n",
    "    # Remove hyperlinks\n",
    "    text = re.sub(r'https?://\\S+', '', text)\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove non-alphanumeric characters and extra whitespaces\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    #text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply the updated cleaning function to the 'text' column in news_df\n",
    "news_df['cleanedText'] = news_df['text'].apply(cleanNews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>language</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>cleanedTitle</th>\n",
       "      <th>cleanedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://kokomoperspective.com/obituaries/jon-w-horton/article_b6ba8e1e-cb9c-11eb-9868-fb11b88b9778.html</td>\n",
       "      <td>2021-06-13</td>\n",
       "      <td>en</td>\n",
       "      <td>Jon W. Horton | Obituaries | kokomoperspective.com</td>\n",
       "      <td>Jon W. Horton | Obituaries | kokomoperspective.comYou have permission to edit this article. EditCloseSign Up                        Log In                    Dashboard  LogoutMy Account Dashboard Profile Saved items LogoutCOVID-19Click here for the latest local news on COVID-19HomeAbout UsContact UsNewsLocalOpinionPoliticsNationalStateAgricultureLifestylesEngagements/Anniversaries/WeddingsAutosEntertainmentHealthHomesOutdoorsSportsNFLNCAAVitalsObituariesAutomotivee-EditionCouponsGalleries74°...</td>\n",
       "      <td>Jon W Horton Obituaries kokomoperspectivecom</td>\n",
       "      <td>Jon W Horton  Obituaries  kokomoperspectivecomYou have permission to edit this article EditCloseSign Up                        Log In                    Dashboard  LogoutMy Account Dashboard Profile Saved items LogoutCOVIDClick here for the latest local news on COVIDHomeAbout UsContact UsNewsLocalOpinionPoliticsNationalStateAgricultureLifestylesEngagementsAnniversariesWeddingsAutosEntertainmentHealthHomesOutdoorsSportsNFLNCAAVitalsObituariesAutomotiveeEditionCouponsGalleriesFair             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://auto.economictimes.indiatimes.com/news/auto-components/birla-precision-to-ramp-up-capacity-to-tap-emerging-opportunities-in-india/81254902</td>\n",
       "      <td>2021-02-28</td>\n",
       "      <td>en</td>\n",
       "      <td>Birla Precision to ramp up capacity to tap emerging opportunities in India, Auto News, ET Auto</td>\n",
       "      <td>Birla Precision to ramp up capacity to tap emerging opportunities in India, Auto News, ET Auto     We have updated our terms and conditions and privacy policy Click \"Continue\" to accept and continue with ET AutoAccept the updated privacy &amp; cookie policyDear user, ET Auto privacy and cookie policy has been updated to align with the new data regulations in European Union. Please review and accept these changes below to continue using the website.You can see our privacy policy &amp; our cookie ...</td>\n",
       "      <td>Birla Precision to ramp up capacity to tap emerging opportunities in India Auto News ET Auto</td>\n",
       "      <td>Birla Precision to ramp up capacity to tap emerging opportunities in India Auto News ET Auto     We have updated our terms and conditions and privacy policy Click Continue to accept and continue with ET AutoAccept the updated privacy  cookie policyDear user ET Auto privacy and cookie policy has been updated to align with the new data regulations in European Union Please review and accept these changes below to continue using the websiteYou can see our privacy policy  our cookie policy We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://ca.sports.yahoo.com/news/global-hydrogen-fueling-station-markets-104800330.html?src=rss</td>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>en</td>\n",
       "      <td>Global Hydrogen Fueling Station Markets to 2035: Current State and Future Prognosis of Passenger Hydrogen Fuel Cell Vehicles (FCVs)</td>\n",
       "      <td>Global Hydrogen Fueling Station Markets to 2035: Current State and Future Prognosis of Passenger Hydrogen Fuel Cell Vehicles (FCVs)        HOME    MAIL    NEWS    SPORTS    FINANCE    CELEBRITY    STYLE    MOVIES    WEATHER    MOBILE           Yahoo Sports Sign in   Mail Sign in to view your mail    Sports Home   Sports Home  Fantasy   Fantasy   Fantasy FootballFantasy Football Fantasy HockeyFantasy Hockey Fantasy BasketballFantasy Basketball Fantasy Auto RacingFantasy Auto Racing Fantasy Go...</td>\n",
       "      <td>Global Hydrogen Fueling Station Markets to 2035 Current State and Future Prognosis of Passenger Hydrogen Fuel Cell Vehicles FCVs</td>\n",
       "      <td>Global Hydrogen Fueling Station Markets to  Current State and Future Prognosis of Passenger Hydrogen Fuel Cell Vehicles FCVs        HOME    MAIL    NEWS    SPORTS    FINANCE    CELEBRITY    STYLE    MOVIES    WEATHER    MOBILE           Yahoo Sports Sign in   Mail Sign in to view your mail    Sports Home   Sports Home  Fantasy   Fantasy   Fantasy FootballFantasy Football Fantasy HockeyFantasy Hockey Fantasy BasketballFantasy Basketball Fantasy Auto RacingFantasy Auto Racing Fantasy GolfFanta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                  url  \\\n",
       "0                                              http://kokomoperspective.com/obituaries/jon-w-horton/article_b6ba8e1e-cb9c-11eb-9868-fb11b88b9778.html   \n",
       "1  https://auto.economictimes.indiatimes.com/news/auto-components/birla-precision-to-ramp-up-capacity-to-tap-emerging-opportunities-in-india/81254902   \n",
       "2                                                     https://ca.sports.yahoo.com/news/global-hydrogen-fueling-station-markets-104800330.html?src=rss   \n",
       "\n",
       "        date language  \\\n",
       "0 2021-06-13       en   \n",
       "1 2021-02-28       en   \n",
       "2 2021-12-07       en   \n",
       "\n",
       "                                                                                                                                 title  \\\n",
       "0                                                                                   Jon W. Horton | Obituaries | kokomoperspective.com   \n",
       "1                                       Birla Precision to ramp up capacity to tap emerging opportunities in India, Auto News, ET Auto   \n",
       "2  Global Hydrogen Fueling Station Markets to 2035: Current State and Future Prognosis of Passenger Hydrogen Fuel Cell Vehicles (FCVs)   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  text  \\\n",
       "0  Jon W. Horton | Obituaries | kokomoperspective.comYou have permission to edit this article. EditCloseSign Up                        Log In                    Dashboard  LogoutMy Account Dashboard Profile Saved items LogoutCOVID-19Click here for the latest local news on COVID-19HomeAbout UsContact UsNewsLocalOpinionPoliticsNationalStateAgricultureLifestylesEngagements/Anniversaries/WeddingsAutosEntertainmentHealthHomesOutdoorsSportsNFLNCAAVitalsObituariesAutomotivee-EditionCouponsGalleries74°...   \n",
       "1      Birla Precision to ramp up capacity to tap emerging opportunities in India, Auto News, ET Auto     We have updated our terms and conditions and privacy policy Click \"Continue\" to accept and continue with ET AutoAccept the updated privacy & cookie policyDear user, ET Auto privacy and cookie policy has been updated to align with the new data regulations in European Union. Please review and accept these changes below to continue using the website.You can see our privacy policy & our cookie ...   \n",
       "2  Global Hydrogen Fueling Station Markets to 2035: Current State and Future Prognosis of Passenger Hydrogen Fuel Cell Vehicles (FCVs)        HOME    MAIL    NEWS    SPORTS    FINANCE    CELEBRITY    STYLE    MOVIES    WEATHER    MOBILE           Yahoo Sports Sign in   Mail Sign in to view your mail    Sports Home   Sports Home  Fantasy   Fantasy   Fantasy FootballFantasy Football Fantasy HockeyFantasy Hockey Fantasy BasketballFantasy Basketball Fantasy Auto RacingFantasy Auto Racing Fantasy Go...   \n",
       "\n",
       "                                                                                                                       cleanedTitle  \\\n",
       "0                                                                                      Jon W Horton Obituaries kokomoperspectivecom   \n",
       "1                                      Birla Precision to ramp up capacity to tap emerging opportunities in India Auto News ET Auto   \n",
       "2  Global Hydrogen Fueling Station Markets to 2035 Current State and Future Prognosis of Passenger Hydrogen Fuel Cell Vehicles FCVs   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           cleanedText  \n",
       "0  Jon W Horton  Obituaries  kokomoperspectivecomYou have permission to edit this article EditCloseSign Up                        Log In                    Dashboard  LogoutMy Account Dashboard Profile Saved items LogoutCOVIDClick here for the latest local news on COVIDHomeAbout UsContact UsNewsLocalOpinionPoliticsNationalStateAgricultureLifestylesEngagementsAnniversariesWeddingsAutosEntertainmentHealthHomesOutdoorsSportsNFLNCAAVitalsObituariesAutomotiveeEditionCouponsGalleriesFair             ...  \n",
       "1      Birla Precision to ramp up capacity to tap emerging opportunities in India Auto News ET Auto     We have updated our terms and conditions and privacy policy Click Continue to accept and continue with ET AutoAccept the updated privacy  cookie policyDear user ET Auto privacy and cookie policy has been updated to align with the new data regulations in European Union Please review and accept these changes below to continue using the websiteYou can see our privacy policy  our cookie policy We...  \n",
       "2  Global Hydrogen Fueling Station Markets to  Current State and Future Prognosis of Passenger Hydrogen Fuel Cell Vehicles FCVs        HOME    MAIL    NEWS    SPORTS    FINANCE    CELEBRITY    STYLE    MOVIES    WEATHER    MOBILE           Yahoo Sports Sign in   Mail Sign in to view your mail    Sports Home   Sports Home  Fantasy   Fantasy   Fantasy FootballFantasy Football Fantasy HockeyFantasy Hockey Fantasy BasketballFantasy Basketball Fantasy Auto RacingFantasy Auto Racing Fantasy GolfFanta...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**News Title - Without Segmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Spacy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import spacy\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "nlp.select_pipes(enable=['ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    organizations = [ent.text for ent in doc.ents if ent.label_ == \"ORG\"]\n",
    "    locations = [ent.text for ent in doc.ents if ent.label_ in [\"LOC\", \"GPE\"]]\n",
    "    return organizations, locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd015ddf28e4c4ba7a8815295e02bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10012 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "news_df['organizations_spacy_spacy'], news_df['locations_spacy_spacy'] = zip(*news_df['cleanedTitle'].progress_apply(extract_entities_spacy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_organizations_spacy = [org for sublist in news_df['organizations_spacy_spacy'] for org in sublist]\n",
    "all_locations_spacy = [loc for sublist in news_df['locations_spacy_spacy'] for loc in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_org = pd.Series(all_organizations_spacy).value_counts().head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 organizations:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Daily Mail                       1068\n",
       "Ford                              360\n",
       "Toyota                            203\n",
       "Chevrolet                         195\n",
       "Hyundai                           180\n",
       "Honda                             155\n",
       "Daily Mail Online                 151\n",
       "Star News                         136\n",
       "Nissan                            108\n",
       "Automotive News                    98\n",
       "EV                                 92\n",
       "BMW                                90\n",
       "Car Dealer Magazine                78\n",
       "Dodge                              76\n",
       "Jeep                               68\n",
       "Otago Daily Times Online News      67\n",
       "CoventryLive                       61\n",
       "Mazda                              58\n",
       "Volkswagen                         55\n",
       "Lexus                              54\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 20 organizations:\")\n",
    "top_20_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_loc = pd.Series(all_locations_spacy).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Location:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Manitoba       140\n",
       "UK             140\n",
       "US             139\n",
       "Winnipeg       137\n",
       "Toronto        120\n",
       "London         101\n",
       "Cambridge       91\n",
       "India           79\n",
       "North York      72\n",
       "Calgary         63\n",
       "Taiwan          56\n",
       "Mississauga     55\n",
       "Scarborough     42\n",
       "Oakville        42\n",
       "Innisfil        41\n",
       "Ottawa          39\n",
       "China           37\n",
       "Australia       36\n",
       "Russia          33\n",
       "Hamilton        32\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 20 Location:\")\n",
    "top_20_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import nltk\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_nltk(text):\n",
    "    entities = []\n",
    "    labels = []\n",
    "    for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(text)), binary=False):\n",
    "        if hasattr(chunk, 'label'):\n",
    "            entities.append(' '.join(c[0] for c in chunk))  # Add space between multi-token entities\n",
    "            labels.append(chunk.label())\n",
    "    entities_labels = list(set(zip(entities, labels)))  # unique entities\n",
    "    organizations = [entity for entity, label in entities_labels if label == \"ORGANIZATION\"]\n",
    "    locations = [entity for entity, label in entities_labels if label == \"GPE\"]\n",
    "    return organizations, locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8c100083b047e596e488e418d47bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10012 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "news_df['organizations_nltk_new'], news_df['locations_nltk_new'] = zip(*news_df['cleanedTitle'].progress_apply(extract_entities_nltk))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_organizations_nltk = [org for orgs in news_df['organizations_nltk_new'] for org in orgs]\n",
    "all_locations_nltk = [loc for locs in news_df['locations_nltk_new'] for loc in locs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_org_nltk = pd.Series(all_organizations_nltk).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 organizations:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Star News            174\n",
       "Daily Mail Online    110\n",
       "Shropshire Star       92\n",
       "MercedesBenz          88\n",
       "Automotive News       85\n",
       "PHL17com              59\n",
       "Business Live         51\n",
       "GMC                   49\n",
       "SUVs                  45\n",
       "NewsBreak             43\n",
       "BMW                   42\n",
       "UK                    42\n",
       "Hindu                 41\n",
       "COVID19               39\n",
       "CarWale               38\n",
       "News Driven           36\n",
       "SUV                   35\n",
       "Auto News             34\n",
       "Fast Lane Car         34\n",
       "Express Star          33\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 20 organizations:\")\n",
    "top_20_org_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_org_nltk = pd.Series(all_locations_nltk).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Location:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sale           1961\n",
       "Prince          147\n",
       "Winnipeg        137\n",
       "New             129\n",
       "Toronto         118\n",
       "London          109\n",
       "India           102\n",
       "China            92\n",
       "Cambridge        91\n",
       "North York       72\n",
       "British          65\n",
       "Calgary          63\n",
       "Taiwan           56\n",
       "Mississauga      55\n",
       "Land             50\n",
       "Kitchener        45\n",
       "Oakville         42\n",
       "Innisfil         41\n",
       "Scarborough      41\n",
       "Ottawa           37\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 20 Location:\")\n",
    "top_20_org_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tweets Title-Sentence segmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Spacy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_spacy(text):\n",
    "    organizations = []\n",
    "    locations_gpe = []\n",
    "    \n",
    "    # Process each sentence individually\n",
    "    doc = nlp(text)\n",
    "    for sent in doc.sents:\n",
    "        sent_ents = nlp(sent.text).ents\n",
    "        organizations.extend([ent.text for ent in sent_ents if ent.label_ == \"ORG\"])\n",
    "        locations_gpe.extend([ent.text for ent in sent_ents if ent.label_ in [\"LOC\", \"GPE\"]])\n",
    "    \n",
    "    return organizations, locations_gpe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7cab8b75fda447b8914b7c15f4ebe8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10012 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "news_df['organizations_spacy_segment_spacy'], news_df['locations_spacy_segment_spacy'] = zip(*news_df['cleanedTitle'].progress_apply(extract_entities_spacy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_organizations_segment = [org for orgs in news_df['organizations_spacy_segment_spacy'] for org in orgs]\n",
    "all_locations_segment = [loc for locs in news_df['locations_spacy_segment_spacy'] for loc in locs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_org_segment = pd.Series(all_organizations_segment).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Daily Mail                       1078\n",
       "Ford                              357\n",
       "Toyota                            204\n",
       "Chevrolet                         196\n",
       "Hyundai                           179\n",
       "Honda                             156\n",
       "Daily Mail Online                 151\n",
       "Star News                         135\n",
       "Automotive News                    98\n",
       "EV                                 93\n",
       "BMW                                90\n",
       "Nissan                             87\n",
       "Car Dealer Magazine                78\n",
       "Jeep                               77\n",
       "Otago Daily Times Online News      67\n",
       "Dodge                              64\n",
       "CoventryLive                       61\n",
       "Mazda                              56\n",
       "Lexus                              54\n",
       "Volkswagen                         47\n",
       "dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20_org_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_loc_segment = pd.Series(all_locations_segment).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UK             140\n",
       "US             140\n",
       "Manitoba       140\n",
       "Winnipeg       137\n",
       "Toronto        120\n",
       "London         101\n",
       "Cambridge       91\n",
       "India           79\n",
       "North York      72\n",
       "Calgary         63\n",
       "Taiwan          56\n",
       "Mississauga     55\n",
       "Oakville        42\n",
       "Scarborough     42\n",
       "Innisfil        41\n",
       "Ottawa          39\n",
       "China           37\n",
       "Australia       36\n",
       "Russia          33\n",
       "Hamilton        32\n",
       "dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20_loc_segment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\MANOJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\MANOJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\MANOJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\MANOJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import nltk\n",
    "\n",
    "# Download NLTK resources if not already downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "def extract_orgs_locs_nltk_segment(text):\n",
    "    organizations = []\n",
    "    locations = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent)), binary=False):\n",
    "            if hasattr(chunk, 'label'):\n",
    "                entity = ' '.join(c[0] for c in chunk)  # Combine multi-token entities\n",
    "                if chunk.label() == 'ORGANIZATION':\n",
    "                    organizations.append(entity)\n",
    "                elif chunk.label() == 'GPE':\n",
    "                    locations.append(entity)\n",
    "    return organizations, locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c938d382f649f6afc8024ee544f23f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10012 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "news_df['organizations_nltk_segment'], news_df['locations_nltk_segment'] = zip(*news_df['cleanedTitle'].progress_apply(extract_orgs_locs_nltk_segment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_organizations_nltk_segment = [org for orgs in news_df['organizations_nltk_segment'] for org in orgs]\n",
    "all_locations_nltk_segment = [loc for locs in news_df['locations_nltk_segment'] for loc in locs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_org_segment_nltk = pd.Series(all_organizations_nltk_segment).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Organizations in Title:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Star News            174\n",
       "Daily Mail Online    110\n",
       "Shropshire Star       92\n",
       "MercedesBenz          88\n",
       "Automotive News       85\n",
       "PHL17com              59\n",
       "Business Live         51\n",
       "GMC                   49\n",
       "SUVs                  45\n",
       "BMW                   43\n",
       "NewsBreak             43\n",
       "UK                    42\n",
       "Hindu                 41\n",
       "COVID19               39\n",
       "CarWale               38\n",
       "News Driven           36\n",
       "SUV                   35\n",
       "Fast Lane Car         34\n",
       "Auto News             34\n",
       "Express Star          33\n",
       "dtype: int64"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 20 Organizations in Title:\")\n",
    "top_20_org_segment_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_loc_segment_nltk = pd.Series(all_locations_nltk_segment).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Location in Title:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sale           1961\n",
       "Prince          147\n",
       "Winnipeg        137\n",
       "New             131\n",
       "Toronto         118\n",
       "London          109\n",
       "India           103\n",
       "China            92\n",
       "Cambridge        91\n",
       "North York       72\n",
       "British          65\n",
       "Calgary          63\n",
       "Taiwan           56\n",
       "Mississauga      55\n",
       "Land             50\n",
       "Kitchener        45\n",
       "Oakville         42\n",
       "Innisfil         41\n",
       "Scarborough      41\n",
       "Ottawa           37\n",
       "dtype: int64"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 20 Location in Title:\")\n",
    "top_20_loc_segment_nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison of Entity Counts Between SpaCy and NLTK**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organizations: SpaCy vs NLTK: Difference in counts of organizations identified by SpaCy compared to NLTK. SpaCy Segment vs SpaCy: Difference in counts of organizations identified by SpaCy with sentence segmentation compared to without segmentation. Locations: SpaCy vs NLTK: Difference in counts of locations identified by SpaCy compared to NLTK. SpaCy Segment vs SpaCy: Difference in counts of locations identified by SpaCy with sentence segmentation compared to without segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing entity counts across different extraction methods or configurations helps identify which method performs better for a given dataset. This insight guides decision-making to optimize entity extraction strategies, improving overall data processing and downstream applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note : Used this because my top 20 count is almost the same, Used this to show comparision*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaCy vs NLTK - Organizations:\n",
      "                              Organization  Difference_Count\n",
      "0                               Daily Mail              1068\n",
      "1                                     Ford               353\n",
      "2                                   Toyota               200\n",
      "3                                Chevrolet               195\n",
      "4                                  Hyundai               178\n",
      "5                                    Honda               154\n",
      "6                        Daily Mail Online                41\n",
      "7                                Star News               -38\n",
      "8                                   Nissan               108\n",
      "9                          Automotive News                13\n",
      "10                                      EV                77\n",
      "11                                     BMW                48\n",
      "12                     Car Dealer Magazine                78\n",
      "13                                   Dodge                76\n",
      "14                                    Jeep                68\n",
      "15           Otago Daily Times Online News                67\n",
      "16                            CoventryLive                44\n",
      "17                                   Mazda                58\n",
      "18                              Volkswagen                40\n",
      "19                                   Lexus                54\n",
      "20                                     Kia                42\n",
      "21                          Prince Philips                20\n",
      "22                       Auto News ET Auto                43\n",
      "23                             Tata Motors                41\n",
      "24                                  Jaguar                40\n",
      "25                                 CarWale                 4\n",
      "26                                    Audi                40\n",
      "27                     AutoSpies Auto News                22\n",
      "28                                   Tesla                38\n",
      "29                              Land Rover                14\n",
      "30                         Shropshire Star               -64\n",
      "31                            MercedesBenz               -87\n",
      "32                                PHL17com               -47\n",
      "33                           Business Live               -41\n",
      "34                                     GMC               -14\n",
      "35                                    SUVs               -45\n",
      "36                               NewsBreak               -43\n",
      "37                                      UK               -42\n",
      "38                                   Hindu               -41\n",
      "39                                 COVID19               -39\n",
      "40                             News Driven               -36\n",
      "41                                     SUV               -35\n",
      "42                               Auto News               -30\n",
      "43                           Fast Lane Car               -34\n",
      "44                            Express Star               -24\n",
      "45                             Mail Online               -31\n",
      "46                                CTV News                -9\n",
      "47                                 SUNROOF               -30\n",
      "48  Abbotsford British Columbia Carpagesca               -27\n",
      "49            Brantford Ontario Carpagesca               -24\n",
      "50                                 WAVYcom                -3\n",
      "51                                      US               -22\n",
      "52                                    Land               -20\n",
      "\n",
      "SpaCy vs NLTK - Locations:\n",
      "          Location  Difference_Count\n",
      "0               UK               140\n",
      "1         Manitoba               139\n",
      "2               US               110\n",
      "3         Winnipeg                 0\n",
      "4          Toronto                 2\n",
      "5           London                -8\n",
      "6        Cambridge                 0\n",
      "7            India               -23\n",
      "8       North York                 0\n",
      "9          Calgary                 0\n",
      "10          Taiwan                 0\n",
      "11     Mississauga                 0\n",
      "12     Scarborough                 1\n",
      "13        Oakville                 0\n",
      "14        Innisfil                 0\n",
      "15          Ottawa                 2\n",
      "16           China               -55\n",
      "17       Australia                 0\n",
      "18          Russia                 1\n",
      "19        Hamilton                 0\n",
      "20        Brampton                 0\n",
      "21          Surrey                30\n",
      "22        Edmonton                 0\n",
      "23         Ukraine                 3\n",
      "24      Abbotsford                27\n",
      "25        Kingston                 0\n",
      "26      Burlington                 0\n",
      "27       Saskatoon                 0\n",
      "28       Brantford                24\n",
      "29         Britain                -1\n",
      "30            Sale             -1954\n",
      "31          Prince              -147\n",
      "32             New              -129\n",
      "33         British               -65\n",
      "34            Land               -50\n",
      "35       Kitchener               -43\n",
      "36           North               -33\n",
      "37      Australian               -31\n",
      "38  Surrey British               -27\n",
      "\n",
      "SpaCy Segment vs SpaCy - Organizations:\n",
      "                     Organization  Difference_Count\n",
      "0                      Daily Mail                10\n",
      "1                            Ford                -3\n",
      "2                          Toyota                 1\n",
      "3                       Chevrolet                 1\n",
      "4                         Hyundai                -1\n",
      "5                           Honda                 1\n",
      "6               Daily Mail Online                 0\n",
      "7                       Star News                -1\n",
      "8                 Automotive News                 0\n",
      "9                              EV                 1\n",
      "10                            BMW                 0\n",
      "11                         Nissan               -21\n",
      "12            Car Dealer Magazine                 0\n",
      "13                           Jeep                 9\n",
      "14  Otago Daily Times Online News                 0\n",
      "15                          Dodge               -12\n",
      "16                   CoventryLive                 0\n",
      "17                          Mazda                -2\n",
      "18                          Lexus                 0\n",
      "19                     Volkswagen                -8\n",
      "20                 Prince Philips                 0\n",
      "21              Auto News ET Auto                 0\n",
      "22                    Tata Motors                 0\n",
      "23                        CarWale                 1\n",
      "24                          Tesla                 2\n",
      "25                         Jaguar                 0\n",
      "26                           Audi                 0\n",
      "27                            Kia                -4\n",
      "28            AutoSpies Auto News                 0\n",
      "29                     Land Rover                 0\n",
      "\n",
      "SpaCy Segment vs SpaCy - Locations:\n",
      "       Location  Difference_Count\n",
      "0            UK                 0\n",
      "1      Manitoba                 0\n",
      "2            US                 1\n",
      "3      Winnipeg                 0\n",
      "4       Toronto                 0\n",
      "5        London                 0\n",
      "6     Cambridge                 0\n",
      "7         India                 0\n",
      "8    North York                 0\n",
      "9       Calgary                 0\n",
      "10       Taiwan                 0\n",
      "11  Mississauga                 0\n",
      "12  Scarborough                 0\n",
      "13     Oakville                 0\n",
      "14     Innisfil                 0\n",
      "15       Ottawa                 0\n",
      "16        China                 0\n",
      "17    Australia                 0\n",
      "18       Russia                 0\n",
      "19     Hamilton                 0\n",
      "20     Brampton                 0\n",
      "21       Surrey                 0\n",
      "22     Edmonton                 0\n",
      "23      Ukraine                 0\n",
      "24   Abbotsford                 0\n",
      "25     Kingston                 0\n",
      "26   Burlington                 0\n",
      "27    Saskatoon                 0\n",
      "28    Brantford                 0\n",
      "29      Britain                 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Function to compute the difference in counts\n",
    "def compute_difference_counts(column1, column2):\n",
    "    # Flatten the columns and count occurrences\n",
    "    counts1 = Counter([word for sublist in column1 for word in sublist])\n",
    "    counts2 = Counter([word for sublist in column2 for word in sublist])\n",
    "    \n",
    "    # Get the top 30 words from each column\n",
    "    top_30_column1 = counts1.most_common(30)\n",
    "    top_30_column2 = counts2.most_common(30)\n",
    "    \n",
    "    # Calculate the difference in counts\n",
    "    difference_counts = {}\n",
    "    for word, count in top_30_column1:\n",
    "        difference_counts[word] = count - counts2.get(word, 0)\n",
    "    for word, count in top_30_column2:\n",
    "        if word not in difference_counts:\n",
    "            difference_counts[word] = counts1.get(word, 0) - count\n",
    "    \n",
    "    return difference_counts\n",
    "\n",
    "# Compute difference in counts for organizations and locations between different columns\n",
    "difference_counts_org_spacy_vs_nltk = compute_difference_counts(news_df['organizations_spacy_spacy'], news_df['organizations_nltk_new'])\n",
    "difference_counts_loc_spacy_vs_nltk = compute_difference_counts(news_df['locations_spacy_spacy'], news_df['locations_nltk_new'])\n",
    "difference_counts_org_spacy_segment_vs_spacy = compute_difference_counts(news_df['organizations_spacy_segment_spacy'], news_df['organizations_spacy_spacy'])\n",
    "difference_counts_loc_spacy_segment_vs_spacy = compute_difference_counts(news_df['locations_spacy_segment_spacy'], news_df['locations_spacy_spacy'])\n",
    "\n",
    "# Create DataFrames to store comparison results\n",
    "org_spacy_vs_nltk_df = pd.DataFrame(difference_counts_org_spacy_vs_nltk.items(), columns=['Organization', 'Difference_Count'])\n",
    "loc_spacy_vs_nltk_df = pd.DataFrame(difference_counts_loc_spacy_vs_nltk.items(), columns=['Location', 'Difference_Count'])\n",
    "org_spacy_segment_vs_spacy_df = pd.DataFrame(difference_counts_org_spacy_segment_vs_spacy.items(), columns=['Organization', 'Difference_Count'])\n",
    "loc_spacy_segment_vs_spacy_df = pd.DataFrame(difference_counts_loc_spacy_segment_vs_spacy.items(), columns=['Location', 'Difference_Count'])\n",
    "\n",
    "# Display the comparison results\n",
    "print(\"SpaCy vs NLTK - Organizations:\")\n",
    "print(org_spacy_vs_nltk_df)\n",
    "print(\"\\nSpaCy vs NLTK - Locations:\")\n",
    "print(loc_spacy_vs_nltk_df)\n",
    "print(\"\\nSpaCy Segment vs SpaCy - Organizations:\")\n",
    "print(org_spacy_segment_vs_spacy_df)\n",
    "print(\"\\nSpaCy Segment vs SpaCy - Locations:\")\n",
    "print(loc_spacy_segment_vs_spacy_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Therefore, choosing SpaCy with text Segmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obseravtions:( News Title)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Most Repetative Organization : Daily Mail**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Most Repetative Location: UK**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**News Text - Without Sentence Segmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Spacy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    organizations = [ent.text for ent in doc.ents if ent.label_ == \"ORG\"]\n",
    "    locations = [ent.text for ent in doc.ents if ent.label_ in [\"LOC\", \"GPE\"]]\n",
    "    return organizations, locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5877bbbec5ad41bc9a23217041f8aca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10012 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "news_df['organizations_spacy'], news_df['locations_spacy'] = zip(*news_df['cleanedText'].progress_apply(extract_entities_spacy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_organizations_spacy = [org for sublist in news_df['organizations_spacy'] for org in sublist]\n",
    "all_locations_spacy = [loc for sublist in news_df['locations_spacy'] for loc in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_org_text = pd.Series(all_organizations_spacy).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 organization:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ford              6420\n",
       "Prince Philips    5968\n",
       "Toyota            5749\n",
       "Netflix           5434\n",
       "Hyundai           4229\n",
       "Honda             4022\n",
       "EV                3983\n",
       "Facebook          3583\n",
       "Amazon            3509\n",
       "Land Rover        3325\n",
       "Instagram         3219\n",
       "Royal             3085\n",
       "Chevrolet         2908\n",
       "BMW               2878\n",
       "Nissan            2540\n",
       "BBC               2296\n",
       "Tesla             2188\n",
       "TikTok            2065\n",
       "Palace            1991\n",
       "House             1971\n",
       "dtype: int64"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 20 organization:\")\n",
    "top_20_org_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_loc_text = pd.Series(all_locations_spacy).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Location:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LA                20156\n",
       "US                13124\n",
       "NYC               12063\n",
       "Los Angeles       10812\n",
       "UK                10239\n",
       "London             9229\n",
       "New York City      8005\n",
       "Hollywood          5672\n",
       "Miami              5345\n",
       "West Hollywood     5185\n",
       "Paris              5045\n",
       "Beverly Hills      4415\n",
       "New York           4272\n",
       "California         4182\n",
       "India              3868\n",
       "Australia          3785\n",
       "Malibu             3526\n",
       "Sydney             3116\n",
       "Texas              3014\n",
       "Las Vegas          2913\n",
       "dtype: int64"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 20 Location:\")\n",
    "top_20_loc_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_nltk(text):\n",
    "    entities = []\n",
    "    labels = []\n",
    "    for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(text)), binary=False):\n",
    "        if hasattr(chunk, 'label'):\n",
    "            entities.append(' '.join(c[0] for c in chunk))  # Add space between multi-token entities\n",
    "            labels.append(chunk.label())\n",
    "\n",
    "    entities_labels = list(set(zip(entities, labels)))  # unique entities\n",
    "    organizations = [entity for entity, label in entities_labels if label == \"ORGANIZATION\"]\n",
    "    locations = [entity for entity, label in entities_labels if label == \"GPE\"]\n",
    "    return organizations, locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c69319365a413b86e910c7140cd389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10012 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "news_df['organizations_nltk_new'], news_df['locations_nltk_new'] = zip(*news_df['cleanedText'].progress_apply(extract_entities_nltk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_organizations_nltk = [org for sublist in news_df['organizations_nltk_new'] for org in sublist]\n",
    "all_locations_nltk = [loc for sublist in news_df['locations_nltk_new'] for loc in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_org_nltk = pd.Series(all_organizations_nltk).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 organization:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "COVID                          3621\n",
       "RomeoAston                     2224\n",
       "UK                             2063\n",
       "MakeAcuraAlfa                  2030\n",
       "Daily                          2024\n",
       "US                             2024\n",
       "insuranceCar                   1984\n",
       "vehicleGet                     1963\n",
       "DealerSite Account             1962\n",
       "Autopath Technologies Inc      1962\n",
       "TopMore                        1961\n",
       "Carpagesca Terms Conditions    1961\n",
       "MailMail                       1948\n",
       "siteReader                     1948\n",
       "PrintsOur                      1948\n",
       "pageDaily                      1948\n",
       "MoneyMetroJobsiteMail          1940\n",
       "usHow                          1919\n",
       "Associated Newspapers          1913\n",
       "UsTermsDo                      1905\n",
       "dtype: int64"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 20 organization:\")\n",
    "top_20_org_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_loc_nltk = pd.Series(all_locations_nltk).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Location:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "London           2443\n",
       "British          2305\n",
       "New              2173\n",
       "Sale             2048\n",
       "Los Angeles      1890\n",
       "New York         1775\n",
       "New York City    1648\n",
       "West             1634\n",
       "Miami            1619\n",
       "French           1614\n",
       "California       1613\n",
       "American         1608\n",
       "Malibu           1545\n",
       "Paris            1533\n",
       "Australian       1487\n",
       "Australia        1448\n",
       "Mexico           1447\n",
       "Facebook         1432\n",
       "Covid            1407\n",
       "China            1307\n",
       "dtype: int64"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 20 Location:\")\n",
    "top_20_loc_nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**News Text - With Sentense Segmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Spacy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_spacy(text):\n",
    "    organizations = []\n",
    "    locations_gpe = []\n",
    "    \n",
    "    # Process each sentence individually\n",
    "    for sent in sent_tokenize(text):\n",
    "        doc = nlp(sent)\n",
    "        organizations.extend([ent.text for ent in doc.ents if ent.label_ == \"ORG\"])\n",
    "        locations_gpe.extend([ent.text for ent in doc.ents if ent.label_ in [\"LOC\", \"GPE\"]])\n",
    "    \n",
    "    return organizations, locations_gpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_nltk(text):\n",
    "    entities = []\n",
    "    labels = []\n",
    "    for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(text)), binary=False):\n",
    "        if hasattr(chunk, 'label'):\n",
    "            entities.append(' '.join(c[0] for c in chunk))  # Add space between multi-token entities\n",
    "            labels.append(chunk.label())\n",
    "    entities_labels = list(set(zip(entities, labels)))  # unique entities\n",
    "    organizations = [entity for entity, label in entities_labels if label == \"ORGANIZATION\"]\n",
    "    locations_gpe = [entity for entity, label in entities_labels if label in [\"GPE\", \"LOC\"]]\n",
    "    return organizations, locations_gpe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269650f98ee445ae915430d632e42c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10012 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "news_df['organizations_spacy_segment'], news_df['locations_spacy_segment'] = zip(*news_df['cleanedText'].progress_apply(extract_entities_spacy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_organizations_spacy_segment = [org for sublist in news_df['organizations_spacy_segment'] for org in sublist]\n",
    "all_locations_spacy_segment = [loc for sublist in news_df['locations_spacy_segment'] for loc in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_org_seg = pd.Series(all_organizations_spacy_segment).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Organization:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "COVID             8414\n",
       "MailOnline        8281\n",
       "KM                4924\n",
       "Toyota            4461\n",
       "Britney Spears    4334\n",
       "Hyundai           3873\n",
       "Instagram         3811\n",
       "Honda             3466\n",
       "Ford              3289\n",
       "Amazon            3042\n",
       "Prince Philips    3041\n",
       "Palace            2825\n",
       "Trump             2689\n",
       "EV                2538\n",
       "Netflix           2443\n",
       "BMW               2302\n",
       "BBC               2164\n",
       "Royal             2147\n",
       "House             2117\n",
       "PrintsOur         1948\n",
       "dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 20 Organization:\")\n",
    "top_20_org_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_loc_seg = pd.Series(all_locations_spacy_segment).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Location:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LA                18149\n",
       "US                12392\n",
       "NYC               10645\n",
       "UK                10311\n",
       "Los Angeles       10033\n",
       "London             9047\n",
       "New York City      7232\n",
       "Hollywood          5570\n",
       "Meghan             5125\n",
       "Miami              4805\n",
       "West Hollywood     4631\n",
       "New York           4405\n",
       "Beverly Hills      4273\n",
       "California         4013\n",
       "India              3974\n",
       "Australia          3686\n",
       "Malibu             3655\n",
       "Paris              3301\n",
       "Sydney             3093\n",
       "Mexico             2985\n",
       "dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 20 Location:\")\n",
    "top_20_loc_seg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_orgs_locs_nltk_segment(text):\n",
    "    organizations = []\n",
    "    locations = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent)), binary=False):\n",
    "            if hasattr(chunk, 'label'):\n",
    "                entity = ' '.join(c[0] for c in chunk)  # Combine multi-token entities\n",
    "                if chunk.label() == 'ORGANIZATION':\n",
    "                    organizations.append(entity)\n",
    "                elif chunk.label() == 'GPE':\n",
    "                    locations.append(entity)\n",
    "    return organizations, locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a6bf212dc044fca1dffe46841d37ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10012 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "news_df['organizations_nltk_segment'], news_df['locations_nltk_segment'] = zip(*news_df['cleanedText'].progress_apply(extract_orgs_locs_nltk_segment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_organizations = [org for orgs in news_df['organizations_nltk_segment'] for org in orgs]\n",
    "all_locations = [loc for locs in news_df['locations_nltk_segment'] for loc in locs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_org = pd.Series(all_organizations).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "COVID             10570\n",
       "MailOnline         8255\n",
       "NYC                8215\n",
       "VERY               6856\n",
       "LA                 4973\n",
       "US                 4422\n",
       "Duke               4291\n",
       "UK                 3992\n",
       "Duchess            3573\n",
       "THE                2593\n",
       "Queen              2364\n",
       "PDA                2337\n",
       "RomeoAston         2309\n",
       "SUV                2242\n",
       "Prince Philips     2214\n",
       "Princess Diana     2165\n",
       "MakeAcuraAlfa      2087\n",
       "insuranceCar       2064\n",
       "Daily              2050\n",
       "BBC                2024\n",
       "dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 20 tokens\")\n",
    "top_20_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_loc = pd.Series(all_locations).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Los Angeles      9561\n",
       "London           8177\n",
       "New York City    7507\n",
       "British          5848\n",
       "New York         4967\n",
       "West             4943\n",
       "Miami            4290\n",
       "India            3889\n",
       "Malibu           3887\n",
       "California       3426\n",
       "New              3394\n",
       "American         3360\n",
       "Paris            3281\n",
       "Australia        3045\n",
       "China            3034\n",
       "Australian       2987\n",
       "Sydney           2792\n",
       "Mexico           2769\n",
       "Sale             2528\n",
       "French           2505\n",
       "dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 20 tokens\")\n",
    "top_20_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Most Repetitive Organization : Ford**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Most Repetative Place : LA ( Los Angeles)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through my analysis of news text data, I've found that utilizing spaCy without sentence segmentation tends to yield superior results compared to approaches involving segmentation. By processing the entire article as a cohesive unit, rather than breaking it into sentences, spaCy can better capture the intricate relationships and contextual nuances present within news articles. This approach enables a more comprehensive understanding of the content, particularly in deciphering complex topics or identifying overarching themes across multiple sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Tweets data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample contains 10,105 tweets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1534565117614084096</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-06-08</td>\n",
       "      <td>Low Orbit Tourist 🌍📷</td>\n",
       "      <td></td>\n",
       "      <td>Body &amp;amp; Assembly - Halewood - United Kingdom\\n🌍53.3504,-2.8352296,402m\\n\\nHalewood Body &amp;amp; Assembly is a Jaguar Land Rover factory in Halewood, England, and forms the major part of the Halewood complex which is shared with Ford who manufacture transmissions at the site. [Wikipedia] https://t.co/LPmCnZIaVt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1534565743429394439</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-06-08</td>\n",
       "      <td>CompleteCar.ie</td>\n",
       "      <td>RT</td>\n",
       "      <td>Land Rover Ireland has announced that the new Range Rover Sport starts at €114,150, now on @completecar:\\n\\nhttps://t.co/TjGUkL3FYr https://t.co/QdVaEiJkjO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id lang       date                  name retweeted  \\\n",
       "0  1534565117614084096   en 2022-06-08  Low Orbit Tourist 🌍📷             \n",
       "1  1534565743429394439   en 2022-06-08        CompleteCar.ie        RT   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                       text  \n",
       "0  Body &amp; Assembly - Halewood - United Kingdom\\n🌍53.3504,-2.8352296,402m\\n\\nHalewood Body &amp; Assembly is a Jaguar Land Rover factory in Halewood, England, and forms the major part of the Halewood complex which is shared with Ford who manufacture transmissions at the site. [Wikipedia] https://t.co/LPmCnZIaVt  \n",
       "1                                                                                                                                                               Land Rover Ireland has announced that the new Range Rover Sport starts at €114,150, now on @completecar:\\n\\nhttps://t.co/TjGUkL3FYr https://t.co/QdVaEiJkjO  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_path = 'https://storage.googleapis.com/msca-bdp-data-open/tweets/nlp_a_5_tweets.json'\n",
    "tweets_df = pd.read_json(tweets_path, orient='records', lines=True)\n",
    "print(f'Sample contains {tweets_df.shape[0]:,.0f} tweets')\n",
    "tweets_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: emoji in c:\\users\\manoj\\appdata\\roaming\\python\\python310\\site-packages (2.10.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import contractions\n",
    "\n",
    "def cleanTweets(text, remove_numbers=True, replace_numbers=False):\n",
    "    # Remove mentions, non-alphabetic characters, and emojis\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+|[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Remove hashtag '#' symbol\n",
    "    text = text.replace('#', '')\n",
    "    \n",
    "    # Remove hyperlinks\n",
    "    text = re.sub(r'(https?://\\S+)|(www\\.\\S+)', '', text)\n",
    "    \n",
    "    # Remove newline characters\n",
    "    text = text.replace('\\n', ' ')\n",
    "    \n",
    "    return text\n",
    "\n",
    "tweets_df['cleanedTweets'] = tweets_df['text'].apply(cleanTweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>text</th>\n",
       "      <th>cleanedTweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1534565117614084096</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-06-08</td>\n",
       "      <td>Low Orbit Tourist 🌍📷</td>\n",
       "      <td></td>\n",
       "      <td>Body &amp;amp; Assembly - Halewood - United Kingdom\\n🌍53.3504,-2.8352296,402m\\n\\nHalewood Body &amp;amp; Assembly is a Jaguar Land Rover factory in Halewood, England, and forms the major part of the Halewood complex which is shared with Ford who manufacture transmissions at the site. [Wikipedia] https://t.co/LPmCnZIaVt</td>\n",
       "      <td>Body amp Assembly  Halewood  United Kingdom m  Halewood Body amp Assembly is a Jaguar Land Rover factory in Halewood England and forms the major part of the Halewood complex which is shared with Ford who manufacture transmissions at the site Wikipedia httpstcoLPmCnZIaVt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1534565743429394439</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-06-08</td>\n",
       "      <td>CompleteCar.ie</td>\n",
       "      <td>RT</td>\n",
       "      <td>Land Rover Ireland has announced that the new Range Rover Sport starts at €114,150, now on @completecar:\\n\\nhttps://t.co/TjGUkL3FYr https://t.co/QdVaEiJkjO</td>\n",
       "      <td>Land Rover Ireland has announced that the new Range Rover Sport starts at  now on   httpstcoTjGUkLFYr httpstcoQdVaEiJkjO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1529341557580652545</td>\n",
       "      <td>en</td>\n",
       "      <td>2022-05-25</td>\n",
       "      <td>Exmoor Trim</td>\n",
       "      <td></td>\n",
       "      <td>New Land Rover Range Rover Hits Top Speed With Ease On Autobahn\\n\\nhttps://t.co/19QOgAIu3v</td>\n",
       "      <td>New Land Rover Range Rover Hits Top Speed With Ease On Autobahn  httpstcoQOgAIuv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id lang       date                  name retweeted  \\\n",
       "0  1534565117614084096   en 2022-06-08  Low Orbit Tourist 🌍📷             \n",
       "1  1534565743429394439   en 2022-06-08        CompleteCar.ie        RT   \n",
       "2  1529341557580652545   en 2022-05-25           Exmoor Trim             \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                       text  \\\n",
       "0  Body &amp; Assembly - Halewood - United Kingdom\\n🌍53.3504,-2.8352296,402m\\n\\nHalewood Body &amp; Assembly is a Jaguar Land Rover factory in Halewood, England, and forms the major part of the Halewood complex which is shared with Ford who manufacture transmissions at the site. [Wikipedia] https://t.co/LPmCnZIaVt   \n",
       "1                                                                                                                                                               Land Rover Ireland has announced that the new Range Rover Sport starts at €114,150, now on @completecar:\\n\\nhttps://t.co/TjGUkL3FYr https://t.co/QdVaEiJkjO   \n",
       "2                                                                                                                                                                                                                                New Land Rover Range Rover Hits Top Speed With Ease On Autobahn\\n\\nhttps://t.co/19QOgAIu3v   \n",
       "\n",
       "                                                                                                                                                                                                                                                                    cleanedTweets  \n",
       "0  Body amp Assembly  Halewood  United Kingdom m  Halewood Body amp Assembly is a Jaguar Land Rover factory in Halewood England and forms the major part of the Halewood complex which is shared with Ford who manufacture transmissions at the site Wikipedia httpstcoLPmCnZIaVt  \n",
       "1                                                                                                                                                        Land Rover Ireland has announced that the new Range Rover Sport starts at  now on   httpstcoTjGUkLFYr httpstcoQdVaEiJkjO  \n",
       "2                                                                                                                                                                                                New Land Rover Range Rover Hits Top Speed With Ease On Autobahn  httpstcoQOgAIuv  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tweets - Without Sentence Segmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using spacy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import spacy\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "nlp.select_pipes(enable=['ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    organizations = [ent.text for ent in doc.ents if ent.label_ == \"ORG\"]\n",
    "    locations_gpe = [ent.text for ent in doc.ents if ent.label_ in [\"LOC\", \"GPE\"]]\n",
    "    return organizations, locations_gpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075ca5cbe1454abb928d80e55f2d49ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets_df['organizations_spacy'], tweets_df['locations_spacy'] = zip(*tweets_df['cleanedTweets'].progress_apply(extract_entities_spacy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Organizations in Tweets (SpaCy):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Land Rover                             1855\n",
       "Jaguar Land Rover                       822\n",
       "eBay                                    412\n",
       "Land Rover Defender                     359\n",
       "Audi Jaguar Land                        290\n",
       "General Motors                          284\n",
       "Jaguar                                  121\n",
       "Ford                                    112\n",
       "Volvo                                   106\n",
       "Land Rover Range                         98\n",
       "SHAMELESS                                93\n",
       "Land Rovers                              80\n",
       "TEKNOOFFICIAL                            77\n",
       "Sikosana                                 76\n",
       "BaT Auctions                             72\n",
       "Rover                                    72\n",
       "BMW                                      66\n",
       "Land Rover Range Rover                   66\n",
       "the SHAMELESS Health Services Board      64\n",
       "Defender                                 64\n",
       "Name: organizations_spacy, dtype: int64"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_organizations_spacy_tweets = tweets_df['organizations_spacy'].explode().value_counts().head(20)\n",
    "print(\"Top 20 Organizations in Tweets (SpaCy):\")\n",
    "top_organizations_spacy_tweets.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 Locations in Tweets (SpaCy):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Russia               471\n",
       "UK                   353\n",
       "httpstcocsoUdvcHc    190\n",
       "NigelAndArron        190\n",
       "Zimbabwe              87\n",
       "Cambridge             85\n",
       "India                 64\n",
       "Hagley                62\n",
       "Jamaica               60\n",
       "LandRover             51\n",
       "London                48\n",
       "Sussex                43\n",
       "weekChase             40\n",
       "US                    38\n",
       "China                 35\n",
       "New Zealand           25\n",
       "France                25\n",
       "Ukraine               24\n",
       "Indias                24\n",
       "Hollywood             24\n",
       "Name: locations_spacy, dtype: int64"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_locations_spacy_tweets = tweets_df['locations_spacy'].explode().value_counts().head(20)\n",
    "print(\"\\nTop 20 Locations in Tweets (SpaCy):\")\n",
    "top_locations_spacy_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_nltk(text):\n",
    "    entities = []\n",
    "    labels = []\n",
    "    for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(text)), binary=False):\n",
    "        if hasattr(chunk, 'label'):\n",
    "            entities.append(' '.join(c[0] for c in chunk))  # Add space between multi-token entities\n",
    "            labels.append(chunk.label())\n",
    "\n",
    "    entities_labels = list(set(zip(entities, labels)))  # unique entities\n",
    "    organizations = [entity for entity, label in entities_labels if label == \"ORGANIZATION\"]\n",
    "    locations = [entity for entity, label in entities_labels if label == \"GPE\"]\n",
    "    return organizations, locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0161ae1f9a7a478da3153c446864b19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets_df['organizations_nltk_new'], tweets_df['locations_nltk_new'] = zip(*tweets_df['cleanedTweets'].progress_apply(extract_entities_nltk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_organizations = [org for orgs in tweets_df['organizations_nltk_new'] for org in orgs]\n",
    "all_locations = [loc for locs in tweets_df['locations_nltk_new'] for loc in locs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_org = pd.Series(all_organizations).value_counts().head(20)\n",
    "top_20_loc = pd.Series(all_locations).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Organizations:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Land Rover                         1371\n",
       "Land                                817\n",
       "eBay                                478\n",
       "Land Rover Discovery                371\n",
       "General Motors                      283\n",
       "httpstcocsoUdvcHc                   190\n",
       "NigelAndArron                       190\n",
       "LAND                                171\n",
       "Duke                                163\n",
       "Duchess                             146\n",
       "UK                                  145\n",
       "ROVER                               135\n",
       "Jaguar Land Rover                   124\n",
       "Jaguar Land                         123\n",
       "SUV                                 118\n",
       "Rover                                77\n",
       "SHAMELESS                            75\n",
       "InvictusGames                        71\n",
       "SHAMELESS Health Services Board      64\n",
       "UKmfg                                64\n",
       "dtype: int64"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 20 Organizations:\")\n",
    "top_20_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 Locations:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Land           1774\n",
       "Russia          436\n",
       "British         184\n",
       "LAND            110\n",
       "Sussex           96\n",
       "Russian          83\n",
       "New              78\n",
       "Zimbabwe         75\n",
       "Car              69\n",
       "Cambridge        68\n",
       "Paracetamol      64\n",
       "Hagley           62\n",
       "Meghan           55\n",
       "India            51\n",
       "Jamaica          50\n",
       "Prince           50\n",
       "Indian           49\n",
       "Kenyan           46\n",
       "Meet             39\n",
       "London           38\n",
       "dtype: int64"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nTop 20 Locations:\")\n",
    "top_20_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tweets - With Sentence Segmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Spacy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_spacy(text):\n",
    "    organizations = []\n",
    "    locations_gpe = []\n",
    "    \n",
    "    # Process each sentence individually\n",
    "    for sent in sent_tokenize(text):\n",
    "        doc = nlp(sent)\n",
    "        organizations.extend([ent.text for ent in doc.ents if ent.label_ == \"ORG\"])\n",
    "        locations_gpe.extend([ent.text for ent in doc.ents if ent.label_ in [\"LOC\", \"GPE\"]])\n",
    "    \n",
    "    return organizations, locations_gpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda1079cc6c44db5a55b4cbd3b7a06db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets_df['organizations_spacy_segment_spacy'], tweets_df['locations_spacy_segment_spacy'] = zip(*tweets_df['cleanedTweets'].progress_apply(extract_entities_spacy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_organizations_spacy_segment = [org for sublist in tweets_df['organizations_spacy_segment_spacy'] for org in sublist]\n",
    "all_locations_spacy_segment = [loc for sublist in tweets_df['locations_spacy_segment_spacy'] for loc in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_org_seg = pd.Series(all_organizations_spacy_segment).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 org:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Land Rover                             1853\n",
       "Jaguar Land Rover                       822\n",
       "eBay                                    412\n",
       "Land Rover Defender                     359\n",
       "Audi Jaguar Land                        290\n",
       "General Motors                          284\n",
       "Jaguar                                  121\n",
       "Ford                                    112\n",
       "Volvo                                   106\n",
       "Land Rover Range                         98\n",
       "SHAMELESS                                93\n",
       "Land Rovers                              80\n",
       "TEKNOOFFICIAL                            77\n",
       "Sikosana                                 76\n",
       "BaT Auctions                             72\n",
       "Rover                                    72\n",
       "Land Rover Range Rover                   66\n",
       "BMW                                      66\n",
       "Defender                                 64\n",
       "the SHAMELESS Health Services Board      64\n",
       "dtype: int64"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 20 org:\")\n",
    "top_20_org_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_loc_seg = pd.Series(all_locations_spacy_segment).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 org:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Russia               471\n",
       "UK                   353\n",
       "NigelAndArron        190\n",
       "httpstcocsoUdvcHc    190\n",
       "Zimbabwe              87\n",
       "Cambridge             85\n",
       "India                 64\n",
       "Hagley                62\n",
       "Jamaica               60\n",
       "LandRover             51\n",
       "London                48\n",
       "Sussex                43\n",
       "weekChase             40\n",
       "US                    38\n",
       "China                 35\n",
       "France                25\n",
       "New Zealand           25\n",
       "Hollywood             24\n",
       "Indias                24\n",
       "Ukraine               24\n",
       "dtype: int64"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 20 org:\")\n",
    "top_20_loc_seg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\MANOJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\MANOJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\MANOJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\MANOJ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import nltk\n",
    "\n",
    "# Download NLTK resources if not already downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "def extract_orgs_locs_nltk_segment(text):\n",
    "    organizations = []\n",
    "    locations = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent)), binary=False):\n",
    "            if hasattr(chunk, 'label'):\n",
    "                entity = ' '.join(c[0] for c in chunk)  # Combine multi-token entities\n",
    "                if chunk.label() == 'ORGANIZATION':\n",
    "                    organizations.append(entity)\n",
    "                elif chunk.label() == 'GPE':\n",
    "                    locations.append(entity)\n",
    "    return organizations, locations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8895d0bdb424714bba0163cf7e53874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets_df['organizations_nltk_segment'], tweets_df['locations_nltk_segment'] = zip(*tweets_df['cleanedTweets'].progress_apply(extract_orgs_locs_nltk_segment))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_organizations = [org for orgs in tweets_df['organizations_nltk_segment'] for org in orgs]\n",
    "all_locations = [loc for locs in tweets_df['locations_nltk_segment'] for loc in locs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_org = pd.Series(all_organizations).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 Organizations:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Land Rover                         1385\n",
       "Land                                822\n",
       "eBay                                478\n",
       "Land Rover Discovery                371\n",
       "General Motors                      283\n",
       "NigelAndArron                       190\n",
       "httpstcocsoUdvcHc                   190\n",
       "LAND                                178\n",
       "Duke                                177\n",
       "SUV                                 170\n",
       "Duchess                             146\n",
       "UK                                  146\n",
       "ROVER                               135\n",
       "Jaguar Land Rover                   124\n",
       "Jaguar Land                         123\n",
       "SHAMELESS                            93\n",
       "Rover                                77\n",
       "InvictusGames                        71\n",
       "SHAMELESS Health Services Board      64\n",
       "httpstcohvbiNbZFs                    64\n",
       "dtype: int64"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top_20_org = org_series.value_counts().head(20)\n",
    "print(\"\\nTop 20 Organizations:\")\n",
    "top_20_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_loc = pd.Series(all_locations).value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 Locations:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Land           1785\n",
       "Russia          464\n",
       "British         188\n",
       "LAND            110\n",
       "Sussex          109\n",
       "Zimbabwe         86\n",
       "Russian          84\n",
       "New              78\n",
       "Car              69\n",
       "Cambridge        68\n",
       "Paracetamol      64\n",
       "India            63\n",
       "Hagley           62\n",
       "Meghan           55\n",
       "Indian           53\n",
       "Jamaica          51\n",
       "Prince           50\n",
       "Kenyan           46\n",
       "Meet             39\n",
       "London           38\n",
       "dtype: int64"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top_20_loc = loc_series.value_counts().head(20)\n",
    "print(\"\\nTop 20 Locations:\")\n",
    "top_20_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Most Repetitive Organization : Land Rover**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Most Repetative Location : Russia**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my analysis of tweet data, I've found that using spaCy with sentence segmentation works better compared to other methods. This is because spaCy accurately identifies entities within each sentence, helping to capture context and relationships more precisely. By leveraging spaCy's pre-trained models and optimized performance, this approach ensures higher accuracy in recognizing organizations and locations mentioned in the tweets. As a result, in my analysis, spaCy with sentence segmentation stands out as the preferred option for extracting detailed insights from tweet data.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
